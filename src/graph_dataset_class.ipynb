{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset de torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compose, NormalizeFeatures\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDataModule\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Batch, Data\n",
    "import random\n",
    "from torch_geometric.transforms import Compose\n",
    "from transformers import AutoTokenizer\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Batch as GeoBatch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "\n",
    "class MaxMinNormalization(BaseTransform):\n",
    "    def __init__(self, max_values=None, min_values=None):\n",
    "        \"\"\"\n",
    "        Initialize the normalization transform with optional max and min values.\n",
    "        If not provided, they should be computed from the dataset.\n",
    "        \"\"\"\n",
    "        self.max_values = max_values if max_values is not None else torch.tensor([76.03170776367188, 77.9359130859375, 88.72427368164062], dtype=torch.float)\n",
    "        self.min_values = min_values if min_values is not None else torch.tensor([-73.90082550048828, -112.23554992675781, -79.38320922851562], dtype=torch.float)\n",
    "\n",
    "    def __call__(self, data: Data) -> Data:\n",
    "        \"\"\"\n",
    "        Apply min-max normalization to the node features.\n",
    "        \"\"\"\n",
    "        data.x = (data.x - self.min_values) / (self.max_values - self.min_values)\n",
    "        return data\n",
    "    \n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "import random\n",
    "\n",
    "\n",
    "class MyLazyDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyLazyDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.transform = Compose([MaxMinNormalization()])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        # De manera similar, lista los archivos en el directorio 'processed'\n",
    "        return os.listdir(os.path.join(self.root, 'processed'))\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # Lista los archivos en el directorio 'raw'\n",
    "        return os.listdir(os.path.join(self.root, 'raw'))\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        \n",
    "        subject = self.processed_file_names[idx]# Seleccionar un sujeto\n",
    "        graphs = torch.load(os.path.join(self.processed_dir, subject))\n",
    "        if self.transform:\n",
    "            graphs = self.transform(graphs)\n",
    "\n",
    "        return graphs\n",
    "\n",
    "\n",
    "# Uso de tu clase de conjunto de datos\n",
    "dataset = MyLazyDataset(root=r'C:\\Users\\pablo\\GitHub\\tfm_prg\\tractoinferno_graphs\\testset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[24849860, 3], edge_index=[2, 49699720], y=[837491], batch=[24849860], ptr=[837492])\n"
     ]
    }
   ],
   "source": [
    "first_element = dataset[0] # Esto carga el primer ejemplo de tu conjunto de datos\n",
    "print(first_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[15249, 3], edge_index=[2, 30498], y=[512], batch=[15249], ptr=[513])\n",
      "torch.Size([512, 32])\n",
      "torch.Size([512, 32])\n",
      "torch.Size([512, 32])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Batch as GeoBatch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "def collate_function(batch):\n",
    "    \"\"\"Funcion para el DataLoader\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    TRACT_LIST = {\n",
    "        'AF_L': {'id': 0, 'tract': 'arcuate fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "        'AF_R': {'id': 1, 'tract': 'arcuate fasciculus','side' : 'right', 'type': 'association'},\n",
    "        'CC_Fr_1': {'id': 2, 'tract': 'corpus callosum, frontal lobe', 'side' : 'most anterior part of the frontal lobe', 'type': 'commissural'},\n",
    "        'CC_Fr_2': {'id': 3, 'tract': 'corpus callosum, frontal lobe', 'side' : 'most posterior part of the frontal lobe','type': 'commissural'},\n",
    "        'CC_Oc': {'id': 4, 'tract': 'corpus callosum, occipital lobe', 'side' : 'central', 'type': 'commissural'},\n",
    "        'CC_Pa': {'id': 5, 'tract': 'corpus callosum, parietal lobe', 'side' : 'central', 'type': 'commissural'},\n",
    "        'CC_Pr_Po': {'id': 6, 'tract': 'corpus callosum, pre/post central gyri', 'side' : 'central', 'type': 'commissural'},\n",
    "        'CG_L': {'id': 7, 'tract': 'cingulum', 'side' : 'left', 'type': 'association'},\n",
    "        'CG_R': {'id': 8, 'tract': 'cingulum', 'side' : 'right', 'type': 'association'},\n",
    "        'FAT_L': {'id': 9, 'tract': 'frontal aslant tract', 'side' : 'left', 'type': 'association'},\n",
    "        'FAT_R': {'id': 10, 'tract': 'frontal aslant tract', 'side' : 'right', 'type': 'association'},\n",
    "        'FPT_L': {'id': 11, 'tract': 'fronto-pontine tract', 'side' : 'left', 'type': 'association'},\n",
    "        'FPT_R': {'id': 12, 'tract': 'fronto-pontine tract', 'side' : 'right', 'type': 'association'},\n",
    "        'FX_L': {'id': 13, 'tract': 'fornix', 'side' : 'left', 'type': 'commissural'},\n",
    "        'FX_R': {'id': 14, 'tract': 'fornix', 'side' : 'right', 'type': 'commissural'},\n",
    "        'IFOF_L': {'id': 15, 'tract': 'inferior fronto-occipital fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "        'IFOF_R': {'id': 16, 'tract': 'inferior fronto-occipital fasciculus', 'side' : 'right', 'type': 'association'},\n",
    "        'ILF_L': {'id': 17, 'tract': 'inferior longitudinal fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "        'ILF_R': {'id': 18, 'tract': 'inferior longitudinal fasciculus', 'side' : 'right', 'type': 'association'},\n",
    "        'MCP': {'id': 19, 'tract': 'middle cerebellar peduncle', 'side' : 'central', 'type': 'commissural'},\n",
    "        'MdLF_L': {'id': 20, 'tract': 'middle longitudinal fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "        'MdLF_R': {'id': 21, 'tract': 'middle longitudinal fasciculus', 'side' : 'right', 'type': 'association'},\n",
    "        'OR_ML_L': {'id': 22, 'tract': 'optic radiation, Meyer loop', 'side' : 'left', 'type': 'projection'},\n",
    "        'OR_ML_R': {'id': 23, 'tract': 'optic radiation, Meyer loop', 'side' : 'right', 'type': 'projection'},\n",
    "        'POPT_L': {'id': 24, 'tract': 'pontine crossing tract', 'side' : 'left', 'type': 'commissural'},\n",
    "        'POPT_R': {'id': 25, 'tract': 'pontine crossing tract', 'side' : 'right', 'type': 'commissural'},\n",
    "        'PYT_L': {'id': 26, 'tract': 'pyramidal tract', 'side' : 'left', 'type': 'projection'},\n",
    "        'PYT_R': {'id': 27, 'tract': 'pyramidal tract', 'side' : 'right', 'type': 'projection'},\n",
    "        'SLF_L': {'id': 28, 'tract': 'superior longitudinal fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "        'SLF_R': {'id': 29, 'tract': 'superior longitudinal fasciculus', 'side' : 'right', 'type': 'association'},\n",
    "        'UF_L': {'id': 30, 'tract': 'uncinate fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "        'UF_R': {'id': 31, 'tract': 'uncinate fasciculus', 'side' : 'right', 'type': 'association'}\n",
    "    }\n",
    "\n",
    "    LABELS = {value[\"id\"]: key for key, value in TRACT_LIST.items()}# Diccionario id -> Etiqueta\n",
    "    caption_templates = [\n",
    "            \"A {type} fiber\",\n",
    "            \"A {type} fiber on the {side} side\",\n",
    "            \"{type} fiber on the {side} side\",\n",
    "            \"A {type} fiber of the {tract}\",\n",
    "            \"{type} fiber of the {tract}\",\n",
    "            \"A {type} fiber of the {tract} on the {side} side\",\n",
    "            \"{type} fiber of the {tract} on the {side} side\",\n",
    "            \"{side} side\",\n",
    "            \"{tract} tract\",\n",
    "            \"{type} fiber\",\n",
    "            \"The {type} fiber located in the {tract} tract\",\n",
    "            \"This is a {type} fiber found on the {side} hemisphere\",\n",
    "            \"Detailed view of a {type} fiber within the {tract}\",\n",
    "            \"Observation of the {type} fiber, prominently on the {side} side\",\n",
    "            \"The {tract} tract's remarkable {type} fiber\",\n",
    "            \"Characteristics of a {type} fiber in the {tract} region\",\n",
    "            \"Notable {type} fiber on the {side} hemisphere of the {tract}\",\n",
    "            \"Insight into the {type} fiber's structure on the {side} side\",\n",
    "            \"Exploring the complexity of the {type} fiber in the {tract}\",\n",
    "            \"The anatomy of a {type} fiber on the {side} hemisphere\",\n",
    "            \"The {tract} tract featuring a {type} fiber\",\n",
    "            \"A comprehensive look at the {type} fiber, {side} orientation\",\n",
    "            \"A closer look at the {type} fiber's path in the {tract}\",\n",
    "            \"Unveiling the {type} fiber's role in the {tract} tract\",\n",
    "            \"Decoding the structure of the {type} fiber on the {side}\",\n",
    "            \"Highlighting the {type} fiber's significance in the {tract}\",\n",
    "            \"The {type} fiber: A journey through the {tract} on the {side}\",\n",
    "            \"A deep dive into the {type} fiber's dynamics in the {tract}\",\n",
    "            \"The {type} fiber's contribution to {tract} tract functionality\",\n",
    "            \"Mapping the {type} fiber's trajectory in the {tract} on the {side} side\",\n",
    "            \"Navigating the intricate pathways of the {type} fiber within the {tract}\",\n",
    "            \"The interplay of {type} fibers across the {side} hemisphere\",\n",
    "            \"Traversing the {tract} with a {type} fiber\",\n",
    "            \"The pivotal role of the {type} fiber in connecting the {tract}\",\n",
    "            \"Showcasing the unique texture of {type} fibers in the {tract}\",\n",
    "            \"Zooming in on the {type} fiber's impact on the {side} hemisphere\",\n",
    "            \"The {type} fiber in the {tract}\",\n",
    "            \"The {type} fiber as a conduit in the {tract} on the {side} side\",\n",
    "            \"The {type} fiber's architectural marvel within the {tract}\",\n",
    "            \"A journey alongside the {type} fiber through the {tract}\",\n",
    "            \"The harmonious structure of the {type} fiber in the {tract}\",\n",
    "            \"Unraveling the secrets of the {type} fiber in the {tract} tract\",\n",
    "            \"The {type} fiber: A key player in {tract} dynamics\",\n",
    "            \"Envisioning the {type} fiber's pathway in the {tract}\",\n",
    "            \"The strategic placement of the {type} fiber in the {tract}\",\n",
    "            \"Illuminating the {type} fiber's route through the {tract}\",\n",
    "            \"The {type} fiber: An essential bridge within the {tract}\",\n",
    "            \"Deciphering the network of {type} fibers in the {tract}\",\n",
    "            \"Exploring the synergy between {type} fibers and the {tract}\",\n",
    "            \"The {type} fiber's vital link in the neural network of the {tract}\"\n",
    "        ]\n",
    "\n",
    "    # Extraer los labels de todos los grafos en el lote\n",
    "    labels = [graph.y.item() for graph in batch]  # Asumiendo que `y` es el tensor de labels\n",
    "    \n",
    "    # Recuperar y tokenizar todos los captions necesarios en una sola llamada\n",
    "    captions = [random.choice(caption_templates).format(**TRACT_LIST[LABELS[label]]) for label in labels]\n",
    "    tokenized_texts_batch = tokenizer(captions, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    # Devolver el lote procesado. No es necesario devolver tokenized_texts_batch por separado\n",
    "\n",
    "    return GeoBatch.from_data_list(batch), tokenized_texts_batch\n",
    "    # return batch, tokenized_texts_batch # grafos, {'input_ids': padded_input_ids, 'attention_mask': padded_attention_masks}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for subject in dataset:\n",
    "    for graph_batch, text_batch in DataLoader(subject, batch_size=512, shuffle=True, num_workers=0, drop_last=True, collate_fn=collate_function):\n",
    "        print(graph_batch)\n",
    "        print(text_batch['input_ids'].shape)\n",
    "        print(text_batch['attention_mask'].shape)\n",
    "        print(text_batch['token_type_ids'].shape)\n",
    "        break\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class MaxMinNormalization(BaseTransform):\n",
    "    def __init__(self, max_values=None, min_values=None):\n",
    "        \"\"\"\n",
    "        Initialize the normalization transform with optional max and min values.\n",
    "        If not provided, they should be computed from the dataset.\n",
    "        \"\"\"\n",
    "        self.max_values = max_values if max_values is not None else torch.tensor([76.03170776367188, 77.9359130859375, 88.72427368164062], dtype=torch.float)\n",
    "        self.min_values = min_values if min_values is not None else torch.tensor([-73.90082550048828, -112.23554992675781, -79.38320922851562], dtype=torch.float)\n",
    "\n",
    "    def __call__(self, data: Data) -> Data:\n",
    "        \"\"\"\n",
    "        Apply min-max normalization to the node features.\n",
    "        \"\"\"\n",
    "        data.x = (data.x - self.min_values) / (self.max_values - self.min_values)\n",
    "        return data\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#Entrenar el modelo utilizando la gpu y tensorboard\n",
    "\n",
    "# print(f\"Using device: {device}\")\n",
    "# model.to(device)\n",
    "# for epoch in range(2):\n",
    "#     for i, (graph_data, text_data) in enumerate(dataloader):\n",
    "#         graph_data = graph_data.to(device)\n",
    "#         text_data = {key: val.to(device) for key, val in text_data.items()}\n",
    "#         loss = model(graph_data, text_data)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         writer.add_scalar('Loss/train', loss, epoch * len(dataloader) + i)\n",
    "#         print(f\"\\r Epoch {epoch}, Iteration {i}, Loss {loss}\")\n",
    "# writer.flush()\n",
    "# writer.close()\n",
    "\n",
    "# Crear un transform customizado para generar captions\n",
    "# transform = Compose([MaxMinNormalization()])\n",
    "\n",
    "# Crear un DataLoader que aplica el transform customizado\n",
    "for subject in dataset:\n",
    "    for batch in subject:\n",
    "        print(batch)\n",
    "        dataloader = DataLoader(batch, batch_size=2048, shuffle=True, collate_fn=)#, transform=transform\n",
    "        for batch in dataloader:\n",
    "            print(batch)\n",
    "            \n",
    "    break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato del dataset\n",
    "\n",
    "# grafos (lista de Data), captions (lista de textos)\n",
    "\n",
    "\n",
    "# Codigo para generar un batch \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataListLoader, DataLoader\n",
    "\n",
    "# def custom_collate_fn(batch):\n",
    "#     graphs = [item['graph'] for item in batch]\n",
    "#     input_ids = [item['text']['input_ids'].squeeze(0) for item in batch]\n",
    "#     attention_masks = [item['text']['attention_mask'].squeeze(0) for item in batch]\n",
    "#     padded_input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "#     padded_attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "#     batched_graphs = GeoBatch.from_data_list(graphs)\n",
    "#     return batched_graphs, {'input_ids': padded_input_ids, 'attention_mask': padded_attention_masks}\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class GraphClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GraphClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 32)\n",
    "        self.conv3 = GCNConv(32, 256)\n",
    "        self.conv4 = GCNConv(256, 512)\n",
    "        self.fc1 = torch.nn.Linear(512, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 32)\n",
    "        self.fc = torch.nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = BatchNorm(x.size()[1])(x)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = BatchNorm(x.size()[1])(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = BatchNorm(x.size()[1])(x)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = BatchNorm(x.size()[1])(x)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = BatchNorm(x.size()[1])(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = BatchNorm(x.size()[1])(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = BatchNorm(x.size()[1])(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = BatchNorm(x.size()[1])(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = GraphClassifier(3, 32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    for subject in dataset:\n",
    "        for batch in tqdm(DataLoader(subject, batch_size=128, shuffle=True)):\n",
    "            data = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "            # print(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre el conjunto de datos\n",
    "for data in dataset:\n",
    "    for batch in DataListLoader(data, batch_size=128, shuffle=True):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader de torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch.shape)\n",
    "    print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddCaptionTransform(BaseTransform):\n",
    "    def __init__(self, tokenize_data=True):\n",
    "        \"\"\"\n",
    "        Initialize the transform with the tokenizer and the tract list.\n",
    "        \"\"\"\n",
    "        self.tokenize_data = tokenize_data\n",
    "\n",
    "        if self.tokenize_data:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        else:\n",
    "            self.tokenizer = None\n",
    "\n",
    "\n",
    "        # Your TRACT_LIST and caption_templates can be defined here\n",
    "        self.TRACT_LIST = {\n",
    "            'AF_L': {'id': 0, 'tract': 'arcuate fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "            'AF_R': {'id': 1, 'tract': 'arcuate fasciculus','side' : 'right', 'type': 'association'},\n",
    "            'CC_Fr_1': {'id': 2, 'tract': 'corpus callosum, frontal lobe', 'side' : 'most anterior part of the frontal lobe', 'type': 'commissural'},\n",
    "            'CC_Fr_2': {'id': 3, 'tract': 'corpus callosum, frontal lobe', 'side' : 'most posterior part of the frontal lobe','type': 'commissural'},\n",
    "            'CC_Oc': {'id': 4, 'tract': 'corpus callosum, occipital lobe', 'side' : 'central', 'type': 'commissural'},\n",
    "            'CC_Pa': {'id': 5, 'tract': 'corpus callosum, parietal lobe', 'side' : 'central', 'type': 'commissural'},\n",
    "            'CC_Pr_Po': {'id': 6, 'tract': 'corpus callosum, pre/post central gyri', 'side' : 'central', 'type': 'commissural'},\n",
    "            'CG_L': {'id': 7, 'tract': 'cingulum', 'side' : 'left', 'type': 'association'},\n",
    "            'CG_R': {'id': 8, 'tract': 'cingulum', 'side' : 'right', 'type': 'association'},\n",
    "            'FAT_L': {'id': 9, 'tract': 'frontal aslant tract', 'side' : 'left', 'type': 'association'},\n",
    "            'FAT_R': {'id': 10, 'tract': 'frontal aslant tract', 'side' : 'right', 'type': 'association'},\n",
    "            'FPT_L': {'id': 11, 'tract': 'fronto-pontine tract', 'side' : 'left', 'type': 'association'},\n",
    "            'FPT_R': {'id': 12, 'tract': 'fronto-pontine tract', 'side' : 'right', 'type': 'association'},\n",
    "            'FX_L': {'id': 13, 'tract': 'fornix', 'side' : 'left', 'type': 'commissural'},\n",
    "            'FX_R': {'id': 14, 'tract': 'fornix', 'side' : 'right', 'type': 'commissural'},\n",
    "            'IFOF_L': {'id': 15, 'tract': 'inferior fronto-occipital fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "            'IFOF_R': {'id': 16, 'tract': 'inferior fronto-occipital fasciculus', 'side' : 'right', 'type': 'association'},\n",
    "            'ILF_L': {'id': 17, 'tract': 'inferior longitudinal fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "            'ILF_R': {'id': 18, 'tract': 'inferior longitudinal fasciculus', 'side' : 'right', 'type': 'association'},\n",
    "            'MCP': {'id': 19, 'tract': 'middle cerebellar peduncle', 'side' : 'central', 'type': 'commissural'},\n",
    "            'MdLF_L': {'id': 20, 'tract': 'middle longitudinal fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "            'MdLF_R': {'id': 21, 'tract': 'middle longitudinal fasciculus', 'side' : 'right', 'type': 'association'},\n",
    "            'OR_ML_L': {'id': 22, 'tract': 'optic radiation, Meyer loop', 'side' : 'left', 'type': 'projection'},\n",
    "            'OR_ML_R': {'id': 23, 'tract': 'optic radiation, Meyer loop', 'side' : 'right', 'type': 'projection'},\n",
    "            'POPT_L': {'id': 24, 'tract': 'pontine crossing tract', 'side' : 'left', 'type': 'commissural'},\n",
    "            'POPT_R': {'id': 25, 'tract': 'pontine crossing tract', 'side' : 'right', 'type': 'commissural'},\n",
    "            'PYT_L': {'id': 26, 'tract': 'pyramidal tract', 'side' : 'left', 'type': 'projection'},\n",
    "            'PYT_R': {'id': 27, 'tract': 'pyramidal tract', 'side' : 'right', 'type': 'projection'},\n",
    "            'SLF_L': {'id': 28, 'tract': 'superior longitudinal fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "            'SLF_R': {'id': 29, 'tract': 'superior longitudinal fasciculus', 'side' : 'right', 'type': 'association'},\n",
    "            'UF_L': {'id': 30, 'tract': 'uncinate fasciculus', 'side' : 'left', 'type': 'association'},\n",
    "            'UF_R': {'id': 31, 'tract': 'uncinate fasciculus', 'side' : 'right', 'type': 'association'}\n",
    "        }\n",
    "\n",
    "        self.LABELS = {value[\"id\"]: key for key, value in self.TRACT_LIST.items()}# Diccionario id -> Etiqueta\n",
    "\n",
    "        self.caption_templates = [\n",
    "            \"A {type} fiber\",\n",
    "            \"A {type} fiber on the {side} side\",\n",
    "            \"{type} fiber on the {side} side\",\n",
    "            \"A {type} fiber of the {tract}\",\n",
    "            \"{type} fiber of the {tract}\",\n",
    "            \"A {type} fiber of the {tract} on the {side} side\",\n",
    "            \"{type} fiber of the {tract} on the {side} side\",\n",
    "            \"{side} side\",\n",
    "            \"{tract} tract\",\n",
    "            \"{type} fiber\",\n",
    "            \"The {type} fiber located in the {tract} tract\",\n",
    "            \"This is a {type} fiber found on the {side} hemisphere\",\n",
    "            \"Detailed view of a {type} fiber within the {tract}\",\n",
    "            \"Observation of the {type} fiber, prominently on the {side} side\",\n",
    "            \"The {tract} tract's remarkable {type} fiber\",\n",
    "            \"Characteristics of a {type} fiber in the {tract} region\",\n",
    "            \"Notable {type} fiber on the {side} hemisphere of the {tract}\",\n",
    "            \"Insight into the {type} fiber's structure on the {side} side\",\n",
    "            \"Exploring the complexity of the {type} fiber in the {tract}\",\n",
    "            \"The anatomy of a {type} fiber on the {side} hemisphere\",\n",
    "            \"The {tract} tract featuring a {type} fiber\",\n",
    "            \"A comprehensive look at the {type} fiber, {side} orientation\",\n",
    "            \"A closer look at the {type} fiber's path in the {tract}\",\n",
    "            \"Unveiling the {type} fiber's role in the {tract} tract\",\n",
    "            \"Decoding the structure of the {type} fiber on the {side}\",\n",
    "            \"Highlighting the {type} fiber's significance in the {tract}\",\n",
    "            \"The {type} fiber: A journey through the {tract} on the {side}\",\n",
    "            \"A deep dive into the {type} fiber's dynamics in the {tract}\",\n",
    "            \"The {type} fiber's contribution to {tract} tract functionality\",\n",
    "            \"Mapping the {type} fiber's trajectory in the {tract} on the {side} side\",\n",
    "            \"Navigating the intricate pathways of the {type} fiber within the {tract}\",\n",
    "            \"The interplay of {type} fibers across the {side} hemisphere\",\n",
    "            \"Traversing the {tract} with a {type} fiber\",\n",
    "            \"The pivotal role of the {type} fiber in connecting the {tract}\",\n",
    "            \"Showcasing the unique texture of {type} fibers in the {tract}\",\n",
    "            \"Zooming in on the {type} fiber's impact on the {side} hemisphere\",\n",
    "            \"The {type} fiber in the {tract}\",\n",
    "            \"The {type} fiber as a conduit in the {tract} on the {side} side\",\n",
    "            \"The {type} fiber's architectural marvel within the {tract}\",\n",
    "            \"A journey alongside the {type} fiber through the {tract}\",\n",
    "            \"The harmonious structure of the {type} fiber in the {tract}\",\n",
    "            \"Unraveling the secrets of the {type} fiber in the {tract} tract\",\n",
    "            \"The {type} fiber: A key player in {tract} dynamics\",\n",
    "            \"Envisioning the {type} fiber's pathway in the {tract}\",\n",
    "            \"The strategic placement of the {type} fiber in the {tract}\",\n",
    "            \"Illuminating the {type} fiber's route through the {tract}\",\n",
    "            \"The {type} fiber: An essential bridge within the {tract}\",\n",
    "            \"Deciphering the network of {type} fibers in the {tract}\",\n",
    "            \"Exploring the synergy between {type} fibers and the {tract}\",\n",
    "            \"The {type} fiber's vital link in the neural network of the {tract}\"\n",
    "        ]\n",
    "\n",
    "\n",
    "    def get_caption(self, data: Data)-> Data:\n",
    "        # print(data.y) -> tensor([ 0,  0,  0,  ..., 29, 29, 29])\n",
    "\n",
    "        captions = []\n",
    "\n",
    "        for label in data.y:\n",
    "            info = self.TRACT_LIST[self.LABELS[label.item()]]\n",
    "            caption = random.choice(self.caption_templates).format(**info)\n",
    "            captions.append(caption)\n",
    "\n",
    "        if self.tokenize_data:\n",
    "            return self.tokenizer(captions, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        else:\n",
    "            return captions\n",
    "\n",
    "    def __call__(self, data: Data) -> Data:\n",
    "        \"\"\"\n",
    "        Add a caption to the data object.\n",
    "        \"\"\"\n",
    "        data.caption = self.get_caption(data)\n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
